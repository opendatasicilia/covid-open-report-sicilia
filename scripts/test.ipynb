{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import feedparser\n",
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfFileReader\n",
    "import re\n",
    "import requests\n",
    "\n",
    "path = \"../download/\"\n",
    "\n",
    "def parsePDF(link, url):\n",
    "    '''\n",
    "    Estrae tutti i links che contengono files .pdf\n",
    "    '''\n",
    "    html = requests.get(link)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        if ('.pdf' in link.get('href')):\n",
    "            pdf = url+link.get('href')\n",
    "    return pdf\n",
    "\n",
    "def getDate(file):\n",
    "    '''\n",
    "    Estrae la data dalla prima pagina del PDF\n",
    "    '''\n",
    "    reader = PdfFileReader(file)\n",
    "    page = reader.getPage(0)\n",
    "    content = page.extractText().replace('\\n','')\n",
    "    match = re.search(r'\\d+/\\d+/\\d+', content)\n",
    "    date = datetime.strptime(match.group(), '%d/%m/%Y').date()\n",
    "\n",
    "    return date\n",
    "\n",
    "def download(pdf):\n",
    "    '''\n",
    "    Scarica il PDF e ritorna il suo path relativo\n",
    "    '''\n",
    "    filename = pdf.rsplit('/',1)[-1]\n",
    "    r = requests.get(pdf, stream=True)\n",
    "    with open(path+filename, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    try: \n",
    "        date = getDate(path+filename)\n",
    "    except:\n",
    "        try: \n",
    "            date = filename.rsplit('/', 1)[-1].replace('%20', '-').rstrip('.pdf').rsplit('-', 3)[1:]\n",
    "            date = datetime.strptime(' '.join(date), '%d %B %Y').date()\n",
    "        except:\n",
    "            date = datetime.now()\n",
    "    finally:\n",
    "        os.rename(path+filename, path+'report-'+date.strftime('%Y%m%d')+'.pdf')\n",
    "    return path+'report-'+date.strftime('%Y%m%d')+'.pdf'\n",
    "\n",
    "def check(url):\n",
    "    '''\n",
    "    Controlla se è uscito un nuovo bollettino\n",
    "    Se si, aggiungilo al report.csv\n",
    "    '''\n",
    "    try:\n",
    "        feed = feedparser.parse(url+'/feed')\n",
    "        f = [field for field in feed['entries'] if (\"bollettino settimanale\" in field['title'].lower() or \"a cura del dasoe\" in field['summary'].lower() or \"Bollettino settimanale Dasoe\" in field['summary'])]\n",
    "        link = f[0]['links'][0]['href']\n",
    "        if(link):\n",
    "            newfile = parsePDF(link, url)\n",
    "            report = pd.read_csv(\"../download/report.csv\")\n",
    "            if newfile not in report.URL.values:\n",
    "                print(\"Nuovo PDF!\")\n",
    "                file = download(newfile)\n",
    "                date = getDate(file)\n",
    "                report = report.append({\"n\":len(report)+1, \"data_report\": date, \"nome_file\": file.rsplit('/', 1)[-1], \"URL\": newfile}, ignore_index=True)\n",
    "                try:\n",
    "                    report.to_csv('../download/report.csv', index=False)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            else:\n",
    "                print(\"PDF già presente in archivio\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfFileReader\n",
    "import tabula\n",
    "\n",
    "path = '../'\n",
    "comuni = pd.DataFrame(pd.read_csv('https://raw.githubusercontent.com/gabacode/vaxExtract/main/utilities/Elenco-comuni-siciliani.csv', converters={'pro_com_t': '{:0>6}'.format}))\n",
    "latest = pd.DataFrame(pd.read_csv(path+'/download/report.csv')).iloc[-1]\n",
    "file = latest['nome_file']\n",
    "date = latest['data_report']\n",
    "\n",
    "def getRanges(file):\n",
    "    '''\n",
    "    Estrae i range delle pagine\n",
    "    Allegato 1 e Allegato 2\n",
    "    '''\n",
    "    result_list = []\n",
    "    r_pages = []\n",
    "\n",
    "    reader = PdfFileReader(file)\n",
    "    pages = reader.numPages\n",
    "\n",
    "    for page_number in range(0, pages):\n",
    "        page = reader.getPage(page_number)\n",
    "        page_content = page.extractText()\n",
    "\n",
    "        if \"ALLEGATO\" in page_content:\n",
    "            result = {\"page\": page_number}\n",
    "            result_list.append(result)\n",
    "\n",
    "    r_pages.append(pages)\n",
    "\n",
    "    for i in range(len(result_list)):\n",
    "        r_pages.append(result_list[i]['page'])\n",
    "\n",
    "    r_pages.sort()\n",
    "\n",
    "    allegati = {\n",
    "        \"file\": file,\n",
    "        \"incidenza\": [r_pages[0], r_pages[1]],\n",
    "        \"vaccini\": [r_pages[1]+1, r_pages[2]]\n",
    "    }\n",
    "\n",
    "    return allegati\n",
    "\n",
    "\n",
    "def isDigit(x):\n",
    "    '''\n",
    "    True se x contiene un numero\n",
    "    '''\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def getVax(vax):\n",
    "    '''\n",
    "    Estrae tabella Vaccini da file PDF\n",
    "    '''\n",
    "    # Leggi il PDF  VAX con tabula-py\n",
    "    print('Leggo tabella Vaccini...attendi...')\n",
    "    pages = list(range(vax['vaccini'][0], vax['vaccini'][1]+1))\n",
    "    pdf = tabula.read_pdf(vax['file'], pages=pages, pandas_options={'header': None}, multiple_tables=True, columns=['103, 607'])\n",
    "    print('Ho letto.')\n",
    "\n",
    "    # Unisci in un unico dataframe e bonifica i dati\n",
    "    vax = pd.concat(pdf).reset_index(drop=True)\n",
    "    vax = vax.dropna(thresh=3).dropna(subset=[0])\n",
    "    vax = vax[~vax[0].str.contains(\"Totale\", na=False)]\n",
    "\n",
    "    for index, row in vax.iterrows():\n",
    "        if(row[0] == \"Santo Stefano di\"):\n",
    "            row[0] = \"Santo Stefano di Camastra\"\n",
    "            \n",
    "    vax = vax.drop([1,2,3], axis=1)\n",
    "    vax.columns = ['comune', 'totale']\n",
    "    vax[['%vaccinati','%immunizzati']] = vax.totale.str.split(expand=True)\n",
    "    vax = vax.drop(['totale'], axis=1)\n",
    "    \n",
    "    vax['%vaccinati'] = vax['%vaccinati'].str.replace(',', '.').str.rstrip('%')\n",
    "    vax['%immunizzati'] = vax['%immunizzati'].str.replace(',', '.').str.rstrip('%')\n",
    "    \n",
    "    vax.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Carica l'helper comuni siciliani\n",
    "    out = pd.merge(vax, comuni, on='comune', how='inner')\n",
    "    out = out[['cod_prov', 'pro_com_t', 'provincia','comune', '%vaccinati', '%immunizzati']]\n",
    "    out['%vaccinati'] = out['%vaccinati'].str.replace(',', '.').str.rstrip('%')\n",
    "    out['%immunizzati'] = out['%immunizzati'].str.replace(',', '.').str.rstrip('%')\n",
    "    out.insert(0, 'data', date)\n",
    "\n",
    "    # Controlla che ci siano tutti i comuni\n",
    "    assert (len(out) == 390), \"Errore: Sono presenti meno comuni del previsto.\"\n",
    "   \n",
    "    # Esporta CSV\n",
    "    print('Esporto CSV...')\n",
    "    out.to_csv(path+'/dati/vaccini/vaccini-'+date.replace(\"-\", \"\")+'.csv', index=None, header=True)\n",
    "    out.to_csv(path+'/dati/vaccini/vaccini-latest.csv', index=None, header=True)\n",
    "    out.to_csv(path+'/dati/vaccini/vaccini.csv', mode='a', index=None, header=False)\n",
    "    csv = path+'/dati/vaccini/vaccini-'+date.replace(\"-\", \"\")+'.csv'\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def getIncidenza(pdf):\n",
    "    '''\n",
    "    Estrae l'incidenza da file PDF\n",
    "    '''\n",
    "    # Legge le pagine relative all'incidenza\n",
    "    print('Leggo tabella Incidenza...attendi...')\n",
    "    reader = PdfFileReader(pdf['file'])\n",
    "    pages = pdf['incidenza']\n",
    "    \n",
    "    # Looppa le pagine, rimuovi numero della pagina e sostituisce breaklines\n",
    "    # aggiunge ad un'unica, grande stringa\n",
    "    textes = []\n",
    "    try:\n",
    "        for i in range(pages[0], pages[-1]+1):\n",
    "            page = reader.getPage(i)\n",
    "            text = page.extractText()\n",
    "            text = text.replace('\\n', ' ')\n",
    "            textes.append(text[2::])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Seleziona parti di interesse, formatta elementi ambigui e ritorna una lista\n",
    "    out = ' '.join(textes)\\\n",
    "        .rpartition('settimane')[2]\\\n",
    "        .rpartition('Totale')[0]\\\n",
    "        .replace('- ', '-')\\\n",
    "        .replace('---', '0%')\\\n",
    "        .replace('  ', ' ')\\\n",
    "        .replace('  ', ' ')\\\n",
    "        .replace('  ', ' ')\\\n",
    "        .replace('%', '')\\\n",
    "        .replace(\"O'\", \"Ò\").replace(\"I'\", \"Ì\").replace(\"U'\", \"Ù\")\\\n",
    "        .split()\n",
    "    \n",
    "    # Riconosce il nome del comune rispetto ad un numero e ritorna una nuova lista\n",
    "    new = \"\"\n",
    "    for split in out:\n",
    "        if not isDigit(split):\n",
    "            new = new + split + ' '\n",
    "        if isDigit(split):\n",
    "            new = new + ',' + split + ','\n",
    "    new = new.replace(',,', ',').replace(\n",
    "        ' ,', ',').replace(' -', '-').split(',')\n",
    "\n",
    "    # Looppa la lista e crea tuple a gruppi di 4\n",
    "    it = iter(new)\n",
    "    data = list(zip(it, it, it, it))\n",
    "    \n",
    "    \n",
    "    # Crea dataframe\n",
    "    df = pd.DataFrame(data, columns=['comune', 'casi', 'incidenza', 'variazione'])\n",
    "    df = df[['comune', 'incidenza', 'casi']]\n",
    "    \n",
    "    # Rimuovi distretti (duplicati)\n",
    "    incidenza = df[~df[\"comune\"].duplicated(keep=\"last\")]\n",
    "    incidenza.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    for index, row in incidenza.iterrows():\n",
    "        if(row[0] == \"SANTA CATERINA\"):\n",
    "            row[0] = \"Santa Caterina Villarmosa\"\n",
    "    \n",
    "    # Inner join e recupera info comuni\n",
    "    out = pd.merge(incidenza, comuni, left_on=incidenza[\"comune\"].str.lower(), right_on=comuni[\"comune\"].str.lower(), how=\"inner\")\n",
    "    out.rename(columns={'comune_y': 'comune'}, inplace=True)\n",
    "    out = out[['cod_prov', 'pro_com_t', 'provincia', 'comune', 'incidenza', 'casi']].sort_values(by=['provincia', 'comune'])\n",
    "    out.reset_index(drop=True, inplace=True)\n",
    "    out.insert(0, 'data', date)\n",
    "\n",
    "    # Controlla che ci siano tutti i comuni\n",
    "    assert (len(out) == 390), \"Errore: Sono presenti meno comuni del previsto.\"\n",
    "\n",
    "    # Esporta CSV\n",
    "    print('Esporto CSV...')\n",
    "    out.to_csv(path+'/dati/incidenza/incidenza-'+date.replace(\"-\", \"\")+'.csv', index=None, header=True)\n",
    "    out.to_csv(path+'/dati/incidenza/incidenza-latest.csv', index=None, header=True)\n",
    "    out.to_csv(path+'/dati/incidenza/incidenza.csv', mode='a', index=None, header=False)\n",
    "    csv = path+'/dati/incidenza/incidenza-'+date.replace(\"-\", \"\")+'.csv'\n",
    "\n",
    "    return csv\n",
    "\n",
    "def addToReadme():\n",
    "    '''\n",
    "    Aggiunge ultima riga del report.csv al file README.md\n",
    "    '''\n",
    "    mesi = {\"01\":\"Gennaio\",\"02\":\"Febbraio\",\"03\":\"Marzo\",\"04\":\"Aprile\",\"05\":\"Maggio\",\"06\":\"Giugno\",\"07\":\"Luglio\",\"08\":\"Agosto\",\"09\":\"Settembre\",\"10\":\"Ottobre\",\"11\":\"Novembre\",\"12\":\"Dicembre\"}\n",
    "    data = date.split('-')\n",
    "    data = data[2] + \" \" + mesi[data[1]] + \" \" + data[0]\n",
    "\n",
    "    title_index = \"\"\n",
    "    with open(\"../README.md\", \"r+\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for index, line in enumerate(lines):\n",
    "            if \"Bollettini pubblicati\" in line:\n",
    "                title_index = index\n",
    "        insert_index = title_index + int(latest['n'])\n",
    "        insert_content = \"- [Report \" + data + \".pdf](\" + latest['URL'] + \")\\n\"\n",
    "        lines.insert(insert_index, insert_content)\n",
    "        f.seek(0)\n",
    "        f.writelines(lines)\n",
    "    f.close()\n",
    "\n",
    "def getAbs(vax):\n",
    "    target = pd.read_csv('https://raw.githubusercontent.com/opendatasicilia/comuni-italiani/main/dati/target5.csv', converters={'pro_com_t': '{:0>6}'.format})\n",
    "    target = target[['pro_com_t','>=5']]\n",
    "    target.columns = ['pro_com_t', 'target']\n",
    "    out_abs = pd.merge(vax, target, on='pro_com_t', how='inner')\n",
    "    out_abs['%vaccinati'] = (out_abs['target'] * out_abs['%vaccinati'].astype(float) / 100).round().astype(int)\n",
    "    out_abs['%immunizzati'] = (out_abs['target'] * out_abs['%immunizzati'].astype(float) / 100).round().astype(int)\n",
    "    out_abs.columns = ['data', 'cod_prov', 'pro_com_t', 'provincia', 'comune', 'vaccinati', 'immunizzati', 'target']\n",
    "    out_abs.to_csv(path+'/dati/vaccini/vaccini-abs-'+date.replace(\"-\", \"\")+'.csv', index=None, header=True)\n",
    "    out_abs.to_csv(path+'/dati/vaccini/vaccini-abs-latest.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496db7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check('https://www.regione.sicilia.it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "getIncidenza(getRanges(path+'/download/'+latest['nome_file']))\n",
    "getVax(getRanges(path+'/download/'+latest['nome_file']))\n",
    "addToReadme()\n",
    "\n",
    "#getAbs(getVax(getRanges(path+'/download/'+latest['nome_file'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987dd600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
